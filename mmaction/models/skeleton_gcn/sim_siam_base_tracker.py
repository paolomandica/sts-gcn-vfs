from mmaction.utils import add_prefix
from .. import builder
from ..common import images2video, video2images
from ..builder import RECOGNIZERS
from .base import BaseTracker


@RECOGNIZERS.register_module()
class SimSiamBaseTracker(BaseTracker):
    """SimSiam framework."""

    def __init__(self, *args, backbone, img_head=None, **kwargs):
        super().__init__(*args, backbone=backbone, **kwargs)
        if img_head is not None:
            self.img_head = builder.build_head(img_head)
        self.init_extra_weights()

    @property
    def with_img_head(self):
        """bool: whether the detector has img head"""
        return hasattr(self, 'img_head') and self.img_head is not None

    def init_extra_weights(self):
        if self.with_img_head:
            self.img_head.init_weights()

    def forward_img_head(self, x1, x2, clip_len):
        if isinstance(x1, tuple):
            x1 = x1[-1]
        if isinstance(x2, tuple):
            x2 = x2[-1]
        losses = dict()
        z1, p1 = self.img_head(x1)
        z2, p2 = self.img_head(x2)
        loss_weight = 1. / clip_len if self.intra_video else 1.
        losses.update(
            add_prefix(
                self.img_head.loss(p1, z1, p2, z2, weight=loss_weight),
                prefix='0'))
        if self.intra_video:
            z2_v, p2_v = images2video(z2, clip_len), images2video(p2, clip_len)
            for i in range(1, clip_len):
                losses.update(
                    add_prefix(
                        self.img_head.loss(
                            p1,
                            z1,
                            video2images(p2_v.roll(i, dims=2)),
                            video2images(z2_v.roll(i, dims=2)),
                            weight=loss_weight),
                        prefix=f'{i}'))
        return losses

    def forward_train(self, skeletons, labels, **kwargs):
        """Defines the computation performed at every call when training."""
        losses = dict()

        breakpoint()

        # skeletons.shape = B,C,T,V,M (64,3,300,25,2)
        B, C, T, V, M = skeletons.shape
        skeletons_1, skeletons_2 = skeletons[:,:,:T//2], skeletons[:,:,T//2:]

        x1 = self.extract_feat(skeletons_1)
        x2 = self.extract_feat(skeletons_2)

        # output = self.cls_head(x)
        # gt_labels = labels.squeeze(-1)
        # loss = self.cls_head.loss(output, gt_labels)
        # losses.update(loss)

        return losses

    def forward_train_old(self, imgs, grids=None, label=None):
        # [B, N, C, T, H, W]
        if self.transpose_temporal:
            imgs = imgs.transpose(1, 3).contiguous()
        assert imgs.size(1) == 2
        assert imgs.ndim == 6
        clip_len = imgs.size(3)
        imgs1 = video2images(imgs[:,
                                  0].contiguous().reshape(-1, *imgs.shape[2:]))
        imgs2 = video2images(imgs[:,
                                  1].contiguous().reshape(-1, *imgs.shape[2:]))
        x1 = self.backbone(imgs1)
        x2 = self.backbone(imgs2)
        losses = dict()
        if self.with_img_head:
            loss_img_head = self.forward_img_head(x1, x2, clip_len)
            losses.update(add_prefix(loss_img_head, prefix='img_head'))

        return losses

    def forward_test(self, imgs, **kwargs):
        raise NotImplementedError
